{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7b5bc30-4c66-4797-bd18-12146c34b020",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import dem_functions as df\n",
    "import bikeability_functions as bf\n",
    "import yan_helper_functions as yhf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d46b68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_metrics(G, dem_SF, total_length_added: int, num_cc: int) -> pd.DataFrame:\n",
    "    betas = np.linspace(0.01, 10, 200)\n",
    "    curves_SF = bf.compute_bikeability_curves(G, G.nodes(), dest=\"all\")\n",
    "    user_dict_SF = bf.network_wide_bikeability_curve(betas, curves_SF)\n",
    "\n",
    "    keys = [\n",
    "        \"frac_pop_nonwhite\",\n",
    "        \"frac_below_poverty\",\n",
    "        \"median_hh_income\",\n",
    "        \"frac_no_car\",\n",
    "    ]\n",
    "    quant_of_int = df.all_quants(keys, dem_SF)\n",
    "    nonwhite_low, nonwhite_high = yhf.quint_curves(G, quant_of_int, \"frac_pop_nonwhite\")\n",
    "    poverty_low, poverty_high = yhf.quint_curves(G, quant_of_int, \"frac_below_poverty\")\n",
    "    income_low, income_high = yhf.quint_curves(G, quant_of_int, \"median_hh_income\")\n",
    "    carless_low, carless_high = yhf.quint_curves(G, quant_of_int, \"frac_no_car\")\n",
    "\n",
    "    new_row = {\n",
    "        \"length_added_bikelanes\": total_length_added,\n",
    "        \"number_cc\": num_cc,\n",
    "        \"overall_score\": bf.calc_elbow(user_dict_SF),\n",
    "        \"nonwhite_high\": bf.calc_elbow(nonwhite_high),\n",
    "        \"nonwhite_low\": bf.calc_elbow(nonwhite_low),\n",
    "        \"poverty_high\": bf.calc_elbow(poverty_high),\n",
    "        \"poverty_low\": bf.calc_elbow(poverty_low),\n",
    "        \"income_high\": bf.calc_elbow(income_high),\n",
    "        \"income_low\": bf.calc_elbow(income_low),\n",
    "        \"carless_high\": bf.calc_elbow(carless_high),\n",
    "        \"carless_low\": bf.calc_elbow(carless_low),\n",
    "    }\n",
    "\n",
    "    return pd.DataFrame([new_row])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "217a470c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def large_to_close(G, G_bikelanes: nx.DiGraph) -> tuple[set, set]:\n",
    "    \"\"\"Returns tuple of sets of nodes in largest connected component and the\n",
    "    closest connected component to the largest of the bike lane graph\n",
    "\n",
    "    Args:\n",
    "        G_bikelanes (nx.DiGraph): Graph of bike lanes\n",
    "\n",
    "    Returns:\n",
    "        tuple[set, set]: Tuple of sets of nodes in largest connected component and the\n",
    "    closest connected component to the largest of the bike lane graph\n",
    "    \"\"\"\n",
    "\n",
    "    ccs = sorted(nx.strongly_connected_components(G_bikelanes), key=len, reverse=True)\n",
    "\n",
    "    # compute centroids of connected components\n",
    "    cc_centroids = []\n",
    "\n",
    "    for component in ccs:\n",
    "        x_list, y_list = [], []\n",
    "\n",
    "        for node in component:\n",
    "            x_list.append(G.nodes[node][\"x\"])\n",
    "            y_list.append(G.nodes[node][\"y\"])\n",
    "\n",
    "        cc_centroids.append((np.mean(x_list), np.mean(y_list)))\n",
    "\n",
    "    # find closest connected component to largest\n",
    "    sqrd_dists = []\n",
    "\n",
    "    for j in cc_centroids:\n",
    "        sqrd_dists.append(\n",
    "            (cc_centroids[0][0] - j[0]) ** 2 + (cc_centroids[0][1] - j[1]) ** 2\n",
    "        )\n",
    "\n",
    "    nodes_cc1 = ccs[0]  # largest connected component\n",
    "    nodes_cc2 = ccs[\n",
    "        np.argsort(sqrd_dists)[1]\n",
    "    ]  # closest connected component to largest connected component\n",
    "\n",
    "    return nodes_cc1, nodes_cc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6821bcf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def large_to_second(G, G_bikelanes: nx.DiGraph) -> tuple[set, set]:\n",
    "    \"\"\"Return tuple of sets of largest connected component and second largest\n",
    "    connected component of G_bikelanes.\n",
    "\n",
    "    Args:\n",
    "        G_bikelanes (nx.DiGraph): Graph of bike lanes.\n",
    "\n",
    "    Returns:\n",
    "        tuple[set, set]: Tuple of sets of largest connected component and second\n",
    "        largest connected component\n",
    "    \"\"\"\n",
    "    ccs = sorted(nx.strongly_connected_components(G_bikelanes), key=len, reverse=True)\n",
    "\n",
    "    nodes_cc1 = ccs[0]  # largest connected component\n",
    "    nodes_cc2 = ccs[1]  # second largest\n",
    "\n",
    "    return nodes_cc1, nodes_cc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58246279",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_to_close(G, G_bikelanes: nx.DiGraph) -> tuple[set, set]:\n",
    "    ccs = sorted(nx.strongly_connected_components(G_bikelanes), key=len, reverse=True)\n",
    "\n",
    "    random_cc_index = np.random.choice(range(len(ccs)))\n",
    "\n",
    "    component_centroids = []\n",
    "\n",
    "    for component in ccs:\n",
    "        x_list = []\n",
    "        y_list = []\n",
    "\n",
    "        for node in component:\n",
    "            x_list.append(G.nodes[node][\"x\"])\n",
    "            y_list.append(G.nodes[node][\"y\"])\n",
    "\n",
    "        component_centroids.append((np.mean(x_list), np.mean(y_list)))\n",
    "\n",
    "    sqrd_dists = []\n",
    "    for j in component_centroids:\n",
    "        sqrd_dists.append(\n",
    "            (component_centroids[random_cc_index][0] - j[0]) ** 2\n",
    "            + (component_centroids[random_cc_index][1] - j[1]) ** 2\n",
    "        )\n",
    "\n",
    "    nodes_cc1 = ccs[random_cc_index]  # random connected component\n",
    "    nodes_cc2 = ccs[\n",
    "        np.argsort(sqrd_dists)[1]\n",
    "    ]  # closest connected component to random connected component\n",
    "\n",
    "    return nodes_cc1, nodes_cc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14878e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def closest_components(G, G_bikelanes: nx.DiGraph) -> tuple[set, set]:\n",
    "    ccs = sorted(nx.strongly_connected_components(G_bikelanes), key=len, reverse=True)\n",
    "\n",
    "    component_centroids = []\n",
    "\n",
    "    for component in ccs:\n",
    "        x_list = []\n",
    "        y_list = []\n",
    "\n",
    "        for node in component:\n",
    "            x_list.append(G.nodes[node][\"x\"])\n",
    "            y_list.append(G.nodes[node][\"y\"])\n",
    "\n",
    "        component_centroids.append((np.mean(x_list), np.mean(y_list)))\n",
    "\n",
    "    pair_dict = {}\n",
    "    for j in range(len(component_centroids)):\n",
    "        sqrd_dists = []\n",
    "        for k in range(len(component_centroids)):\n",
    "            sqrd_dists.append(\n",
    "                (component_centroids[j][0] - component_centroids[k][0]) ** 2\n",
    "                + (component_centroids[j][1] - component_centroids[k][1]) ** 2\n",
    "            )\n",
    "\n",
    "        pair_dict[sqrd_dists[np.argsort(sqrd_dists)[1]]] = (\n",
    "            np.argsort(sqrd_dists)[1],\n",
    "            j,\n",
    "        )\n",
    "\n",
    "    j, k = pair_dict[min(pair_dict.keys())]\n",
    "\n",
    "    nodes_cc1 = ccs[j]  # closest component 1\n",
    "    nodes_cc2 = ccs[k]  # closest component 2\n",
    "    return nodes_cc1, nodes_cc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0d3dd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def gen_new_graph(alg):\n",
    "#     \"\"\"_summary_\n",
    "\n",
    "#     Args:\n",
    "#         alg (_type_): _description_\n",
    "#     \"\"\"\n",
    "#     len_constr_bike_lanes = 0\n",
    "\n",
    "#     G_SF, dem_SF = yhf.load_sf_data()\n",
    "\n",
    "#     G_new = nx.DiGraph()\n",
    "#     G_new.add_nodes_from(G.nodes(data=True))\n",
    "\n",
    "#     while len_constr_bike_lanes < 1000 * 100:\n",
    "#         G_bikelanes = nx.DiGraph()  # graph of all bikelanes\n",
    "#         G_bikelanes.add_nodes_from(G.nodes(data=True))\n",
    "#         G_potential_bikelanes = (\n",
    "#             nx.DiGraph()\n",
    "#         )  # graph of all potential bikelanes (i.e., roads and stroads)\n",
    "#         G_potential_bikelanes.add_nodes_from(G.nodes(data=True))\n",
    "\n",
    "#         # create bikelane and potential bikelane networks\n",
    "#         for start_node, end_node, data in G.edges(data=True):\n",
    "#             if not np.isnan(data[\"distance\"][0]):\n",
    "#                 G_bikelanes.add_edge(start_node, end_node, distance=data[\"distance\"][0])\n",
    "\n",
    "#             G_potential_bikelanes.add_edge(\n",
    "#                 start_node, end_node, distance=np.nanmin(data[\"distance\"])\n",
    "#             )\n",
    "\n",
    "#         num_cc = nx.number_strongly_connected_components(G_bikelanes)\n",
    "\n",
    "#         if num_cc == 1:\n",
    "#             break\n",
    "\n",
    "#         nodes_cc1, nodes_cc2 = alg(G, G_bikelanes, True)\n",
    "\n",
    "#         source_from_cc1 = None\n",
    "#         target_from_cc1 = None\n",
    "#         shortest_dist_from_cc1 = np.inf\n",
    "\n",
    "#         source_to_cc1 = None\n",
    "#         target_to_cc1 = None\n",
    "#         shortest_dist_to_cc1 = np.inf\n",
    "\n",
    "#         # compute shortest path from cc1 to cc2\n",
    "#         for j in nodes_cc1:\n",
    "#             for k in nodes_cc2:\n",
    "#                 if nx.has_path(G_potential_bikelanes, source=j, target=k):\n",
    "#                     dist = nx.shortest_path_length(\n",
    "#                         G_potential_bikelanes, source=j, target=k, weight=\"distance\"\n",
    "#                     )\n",
    "\n",
    "#                     if dist < shortest_dist_from_cc1:\n",
    "#                         source_from_cc1 = j\n",
    "#                         target_from_cc1 = k\n",
    "\n",
    "#         # compute shortest path from cc2 to cc1\n",
    "#         for j in nodes_cc2:\n",
    "#             for k in nodes_cc1:\n",
    "#                 if nx.has_path(G_potential_bikelanes, source=j, target=k):\n",
    "#                     dist = nx.shortest_path_length(\n",
    "#                         G_potential_bikelanes, source=j, target=k, weight=\"distance\"\n",
    "#                     )\n",
    "\n",
    "#                     if dist < shortest_dist_to_cc1:\n",
    "#                         source_to_cc1 = j\n",
    "#                         target_to_cc1 = k\n",
    "\n",
    "#         # construct new bike_lanes on G_SF and G_bikelanes\n",
    "#         short_path_from = nx.shortest_path(\n",
    "#             G_potential_bikelanes,\n",
    "#             source=source_from_cc1,\n",
    "#             target=target_from_cc1,\n",
    "#             weight=\"distance\",\n",
    "#         )\n",
    "#         short_path_to = nx.shortest_path(\n",
    "#             G_potential_bikelanes,\n",
    "#             source=source_to_cc1,\n",
    "#             target=target_to_cc1,\n",
    "#             weight=\"distance\",\n",
    "#         )\n",
    "\n",
    "#         for j in range(len(short_path_from) - 1):\n",
    "#             start_node = short_path_from[j]\n",
    "#             end_node = short_path_from[j + 1]\n",
    "\n",
    "#             len_new = np.nanmin(G[start_node][end_node][0][\"distance\"])\n",
    "#             len_old = G[start_node][end_node][0][\"distance\"][0]\n",
    "\n",
    "#             if np.isnan(len_old) or len_new < G[start_node][end_node][0][\"distance\"][0]:\n",
    "#                 G[start_node][end_node][0][\"distance\"][0] = len_new\n",
    "#                 len_constr_bike_lanes += len_new\n",
    "#                 G_new.add_edge(start_node, end_node)\n",
    "\n",
    "#         for j in range(len(short_path_to) - 1):\n",
    "#             start_node = short_path_to[j]\n",
    "#             end_node = short_path_to[j + 1]\n",
    "\n",
    "#             len_new = np.nanmin(G[start_node][end_node][0][\"distance\"])\n",
    "#             len_old = G[start_node][end_node][0][\"distance\"][0]\n",
    "\n",
    "#             if np.isnan(len_old) or len_new < G[start_node][end_node][0][\"distance\"][0]:\n",
    "#                 G[start_node][end_node][0][\"distance\"][0] = len_new\n",
    "#                 len_constr_bike_lanes += len_new\n",
    "#                 G_new.add_edge(start_node, end_node)\n",
    "\n",
    "#     return G_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1dde5fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # old algs map plot\n",
    "# algs = [large_to_close, large_to_second, random_to_close, closest_components]\n",
    "# new_graphs = []\n",
    "\n",
    "# for alg in algs: new_graphs.append(gen_new_graph(alg))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44f9f0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# algs = [\"large_to_close\", \"large_to_second\", \"random_to_close\", \"closest_components\"]\n",
    "# keys = ['frac_pop_nonwhite','frac_below_poverty','median_hh_income','frac_no_car']\n",
    "\n",
    "# fig, axs = plt.subplots(nrows=4, ncols=4, figsize=(8, 8), sharex=True, sharey=True)\n",
    "\n",
    "# for j, key in enumerate(keys):\n",
    "\n",
    "#     if key in ['median_hh_income']:\n",
    "#         dis_nodes, priv_nodes = df.all_quants([key], dem)[key]\n",
    "#     else:\n",
    "#         priv_nodes, dis_nodes = df.all_quants([key], dem)[key]\n",
    "#     other_nodes = []\n",
    "\n",
    "#     for node in G.nodes:\n",
    "#         if node not in dis_nodes and node not in priv_nodes: other_nodes.append(node)\n",
    "\n",
    "#     coords = [nx.get_node_attributes(G,'x'), nx.get_node_attributes(G,'y')]\n",
    "#     node_pos = {}\n",
    "    \n",
    "#     for k in coords[0].keys():\n",
    "#         node_pos[k] = tuple(d[k] for d in coords)\n",
    "#     for i, G in enumerate(new_graphs):\n",
    "#         nx.draw_networkx_edges(G, pos = node_pos, arrowsize=6.6, width = .66,ax=axs[i][j])\n",
    "#         cx.add_basemap(ax=axs[i][j], source=cx.providers.CartoDB.Positron,\n",
    "#         attribution_size=4)\n",
    "        \n",
    "#         # axs[i][j].set_xlabel(key)\n",
    "#         # axs[i][j].set_ylabel(algs[i])\n",
    "\n",
    "#         nx.draw_networkx_nodes(G, pos = node_pos, ax=axs[i][j], nodelist=dis_nodes, node_color='red', node_size=2, label=\"Privileged\")\n",
    "#         nx.draw_networkx_nodes(G, pos=node_pos, ax=axs[i][j], nodelist=priv_nodes, node_color='green', node_size=2, label='Disadvantaged') \n",
    "#         nx.draw_networkx_nodes(G, pos=node_pos, ax=axs[i][j], nodelist=other_nodes, node_color='gray', node_size=2, label='Other')\n",
    "\n",
    "# algs = [\"Largest-to-Closest\", \"Largest-to-Second\", \"Random-to-Closest\", \"Closest-Components\"]\n",
    "# keys = ['Proportion Non-White','Proportion in Poverty','Median Household Income','Proportion with No Car']\n",
    "\n",
    "# for i, key in enumerate(keys):\n",
    "#     axs[3][i].set_xlabel(key)  \n",
    "\n",
    "# for i, alg in enumerate(algs):\n",
    "#     axs[i][0].set_ylabel(alg)  \n",
    "\n",
    "# handles, labels = axs[0][0].get_legend_handles_labels()\n",
    "# unique_labels = ['Disadvantaged', 'Privileged', 'Other']\n",
    "# unique_handles = [handle for handle, label in zip(handles, labels) if label in unique_labels]\n",
    "# fig.legend(handles=unique_handles, labels=unique_labels, loc='center', bbox_to_anchor=(0.5, 0), ncol=3)\n",
    "# plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "753ad475",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_data(alg) -> pd.DataFrame:\n",
    "\n",
    "    len_constr_bike_lanes = 0\n",
    "\n",
    "\n",
    "    G_SF, dem_SF = yhf.load_sf_data()\n",
    "\n",
    "\n",
    "    dataframe = pd.DataFrame(\n",
    "        columns=[\n",
    "            \"length_added_bikelanes\",\n",
    "            \"number_cc\",\n",
    "            \"overall_score\",\n",
    "            \"nonwhite_high\",\n",
    "            \"nonwhite_low\",\n",
    "            \"poverty_high\",\n",
    "            \"poverty_low\",\n",
    "            \"income_high\",\n",
    "            \"income_low\",\n",
    "            \"carless_high\",\n",
    "            \"carless_low\",\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # graph of all bikelanes\n",
    "    G_bikelanes = nx.DiGraph()\n",
    "\n",
    "    # graph of all potential bikelanes (i.e., roads and stroads)\n",
    "    G_potential_bikelanes = nx.DiGraph()\n",
    "    G_potential_bikelanes.add_nodes_from(G_SF.nodes(data=True))\n",
    "\n",
    "    # create bikelane and potential bikelane networks\n",
    "    for start_node, end_node, data in G_SF.edges(data=True):\n",
    "        if not np.isnan(data[\"distance\"][0]):\n",
    "            G_bikelanes.add_edge(start_node, end_node, distance=data[\"distance\"][0])\n",
    "\n",
    "        G_potential_bikelanes.add_edge(\n",
    "            start_node, end_node, distance=np.nanmin(data[\"distance\"])\n",
    "        )\n",
    "\n",
    "    num_cc = nx.number_strongly_connected_components(G_bikelanes)\n",
    "\n",
    "    dataframe = pd.concat([dataframe, calc_metrics(G_SF, dem_SF, len_constr_bike_lanes, num_cc)])\n",
    "\n",
    "\n",
    "    while len_constr_bike_lanes < 1000 * 50:\n",
    "        print(\"Length of Constructed Bikelanes\", len_constr_bike_lanes)\n",
    "\n",
    "        # graph of all bikelanes\n",
    "        G_bikelanes = nx.DiGraph()\n",
    "\n",
    "        # graph of all potential bikelanes (i.e., roads and stroads)\n",
    "        G_potential_bikelanes = nx.DiGraph()\n",
    "        G_potential_bikelanes.add_nodes_from(G_SF.nodes(data=True))\n",
    "\n",
    "        # create bikelane and potential bikelane networks\n",
    "        for start_node, end_node, data in G_SF.edges(data=True):\n",
    "            if not np.isnan(data[\"distance\"][0]):\n",
    "                G_bikelanes.add_edge(start_node, end_node, distance=data[\"distance\"][0])\n",
    "\n",
    "            G_potential_bikelanes.add_edge(\n",
    "                start_node, end_node, distance=np.nanmin(data[\"distance\"])\n",
    "            )\n",
    "\n",
    "        num_cc = nx.number_strongly_connected_components(G_bikelanes)\n",
    "\n",
    "        if num_cc == 1:\n",
    "            break\n",
    "\n",
    "        nodes_cc1, nodes_cc2 = alg(G_SF, G_bikelanes)\n",
    "\n",
    "\n",
    "        source_from_cc1 = None\n",
    "        target_from_cc1 = None\n",
    "        shortest_dist_from_cc1 = np.inf\n",
    "\n",
    "        source_to_cc1 = None\n",
    "        target_to_cc1 = None\n",
    "        shortest_dist_to_cc1 = np.inf\n",
    "\n",
    "        # compute shortest path from cc1 to cc2\n",
    "\n",
    "\n",
    "        for j in nodes_cc1:\n",
    "\n",
    "\n",
    "            for k in nodes_cc2:\n",
    "                if nx.has_path(G_potential_bikelanes, source=j, target=k):\n",
    "                    dist = nx.shortest_path_length(\n",
    "                        G_potential_bikelanes, source=j, target=k, weight=\"distance\"\n",
    "                    )\n",
    "\n",
    "                    if dist < shortest_dist_from_cc1:\n",
    "                        source_from_cc1, target_from_cc1 = j, k\n",
    "\n",
    "        # compute shortest path from cc2 to cc1\n",
    "        for j in nodes_cc2:\n",
    "            for k in nodes_cc1:\n",
    "                if nx.has_path(G_potential_bikelanes, source=j, target=k):\n",
    "                    dist = nx.shortest_path_length(\n",
    "                        G_potential_bikelanes, source=j, target=k, weight=\"distance\"\n",
    "                    )\n",
    "\n",
    "                    if dist < shortest_dist_to_cc1:\n",
    "                        source_to_cc1, target_to_cc1 = j, k\n",
    "\n",
    "        # construct new bike_lanes on G_SF and G_bikelanes\n",
    "        short_path_from = nx.shortest_path(\n",
    "            G_potential_bikelanes,\n",
    "            source=source_from_cc1,\n",
    "            target=target_from_cc1,\n",
    "            weight=\"distance\",\n",
    "        )\n",
    "        short_path_to = nx.shortest_path(\n",
    "            G_potential_bikelanes,\n",
    "            source=source_to_cc1,\n",
    "            target=target_to_cc1,\n",
    "            weight=\"distance\",\n",
    "        )\n",
    "\n",
    "        for j in range(len(short_path_from) - 1):\n",
    "            start_node = short_path_from[j]\n",
    "            end_node = short_path_from[j + 1]\n",
    "\n",
    "            len_new = G_potential_bikelanes[start_node][end_node][\"distance\"]\n",
    "            len_old = G_SF[start_node][end_node][0][\"distance\"][0]\n",
    "\n",
    "            if np.isnan(len_old) or len_new < len_old:\n",
    "                G_SF[start_node][end_node][0][\"distance\"][0] = len_new\n",
    "                len_constr_bike_lanes += len_new\n",
    "\n",
    "        for j in range(len(short_path_to) - 1):\n",
    "            start_node = short_path_to[j]\n",
    "            end_node = short_path_to[j + 1]\n",
    "\n",
    "            len_new = G_potential_bikelanes[start_node][end_node][\"distance\"]\n",
    "            len_old = G_SF[start_node][end_node][0][\"distance\"][0]\n",
    "\n",
    "            if np.isnan(len_old) or len_new < len_old:\n",
    "                G_SF[start_node][end_node][0][\"distance\"][0] = len_new\n",
    "                len_constr_bike_lanes += len_new\n",
    "\n",
    "        prev_update_len = dataframe.iloc[-1][\"length_added_bikelanes\"]\n",
    "\n",
    "        if len_constr_bike_lanes // 1000 >= prev_update_len // 1000 + 10:\n",
    "            num_cc = nx.number_strongly_connected_components(G_bikelanes)\n",
    "            dataframe = pd.concat(\n",
    "                [dataframe, calc_metrics(G_SF, dem_SF, len_constr_bike_lanes, num_cc)]\n",
    "            )\n",
    "\n",
    "    # final calculations\n",
    "    num_cc = nx.number_strongly_connected_components(G_bikelanes)\n",
    "    dataframe = pd.concat([dataframe, calc_metrics(G_SF, dem_SF, len_constr_bike_lanes, num_cc)])\n",
    "\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f8302ece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched: San Francisco,CA to San Francisco city within layer Incorporated Places\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ckaz3\\Documents\\Academics\\College\\cycling-equity-master\\cycling-equity-master\\dem_functions.py:8: FutureWarning: The `op` parameter is deprecated and will be removed in a future release. Please use the `predicate` parameter instead.\n",
      "  dem = acs.from_place(place,level='tract',place_type='Incorporated Place',variables=list(acs_vars.keys()))\n",
      "C:\\Users\\ckaz3\\AppData\\Local\\Temp\\ipykernel_23340\\1654544188.py:43: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  dataframe = pd.concat([dataframe, calc_metrics(G_SF, dem_SF, len_constr_bike_lanes, num_cc)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Constructed Bikelanes 0\n",
      "Length of Constructed Bikelanes 261.14866666666666\n",
      "Length of Constructed Bikelanes 1180.7960285714285\n",
      "Length of Constructed Bikelanes 2452.3587875\n",
      "Length of Constructed Bikelanes 2840.2949980263156\n",
      "Length of Constructed Bikelanes 4764.369340315154\n",
      "Length of Constructed Bikelanes 6411.262673648487\n",
      "Length of Constructed Bikelanes 9843.15414471293\n"
     ]
    }
   ],
   "source": [
    "algs = [large_to_close, large_to_second, random_to_close, closest_components]\n",
    "alg_names = [\"l2c\", \"l22\", \"r2c\", \"cc\"]\n",
    "\n",
    "for alg, name in zip(algs, alg_names):\n",
    "    gen_data(alg).to_csv(\"data/\" + name + \".csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
